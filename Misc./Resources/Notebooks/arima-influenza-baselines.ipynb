{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Forked and edited from the https://www.kaggle.com/mertcaglar/sarimax-baseline-starter-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in libraries\n"
     ]
    }
   ],
   "source": [
    "print(\"Read in libraries\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in train file\n"
     ]
    }
   ],
   "source": [
    "print(\"read in train file\")\n",
    "df=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/train.csv\",\n",
    "               usecols=['Province_State','Country_Region','Date','ConfirmedCases','Fatalities'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill blanks and add region for counting\n"
     ]
    }
   ],
   "source": [
    "print(\"fill blanks and add region for counting\")\n",
    "df.fillna(' ',inplace=True)\n",
    "df['Lat']=df['Province_State']+df['Country_Region']\n",
    "df.drop('Province_State',axis=1,inplace=True)\n",
    "df.drop('Country_Region',axis=1,inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 294 regions in our dataset\n"
     ]
    }
   ],
   "source": [
    "countries_list=df.Lat.unique()\n",
    "df1=[]\n",
    "for i in countries_list:\n",
    "    df1.append(df[df['Lat']==i])\n",
    "print(\"we have \"+ str(len(df1))+\" regions in our dataset\")\n",
    "\n",
    "#read in test file \n",
    "test=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-2/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papers that Informed Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on how to determine the ARIMA / SARIMA model \n",
    "#https://www.sciencedirect.com/science/article/pii/S1201971218344618\n",
    "\n",
    "A total of 1,341 specimens were positive for influenza A and 490 for influenza B. The majority of infected patients were 1–11 years old (87.7%). The ARIMA model could effectively predict the positive rate of influenza virus in a short time. ARIMA(0,0,11), SARIMA(1,0,0)(0,1,1)12, ARIMA(0,0,1) and SARIMA(0,0,1)(1,0,1)12 were suitable for B(Victoria), B(Yamagata), A(H1N1)pdm09, and A(H3N2), respectively.\n",
    "\n",
    "#https://journals.lww.com/md-journal/fulltext/2016/06280/time_series_analysis_of_influenza_incidence_in.15.aspx\n",
    " It is conceivable that SARIMA (0,1,1)(0,1,1)12 could simultaneously forecast the influenza incidence of the Hebei Province, Guizhou Province, Henan Province, and Shandong Province; SARIMA (1,0,0)(0,1,1)12 could forecast the influenza incidence in Gansu Province; SARIMA (3,1,1)(0,1,1)12 could forecast the influenza incidence in Tianjin City; and SARIMA (0,1,1)(0,0,1)12 could forecast the influenza incidence in Hunan Province. Time series analysis is a good tool for prediction of disease incidence.\n",
    " \n",
    " #https://www.researchgate.net/publication/337619595_Predicting_Seasonal_Influenza_Based_on_SARIMA_Model_in_Mainland_China_from_2005_to_2018\n",
    " The SARIMA (1, 0, 0) × (0, 1, 1) 12 model predicted that the influenza incidence in 2018 was similar to that of previous years, and it fitted the seasonal fluctuation. The relative errors between actual values and predicted values fluctuated from 0.0010 to 0.0137, which indicated that the predicted values matched the actual values well. This study demonstrated that the SARIMA model could effectively make short-term predictions of seasonal influenza.\n",
    " \n",
    " #https://www.mdpi.com/1660-4601/17/4/1381/htm\n",
    "  For the SARIMA and ARIMA models, AICc-based model selection using the training data resulted in SARIMA(1,0,0)(1,1,0)[52] and ARIMA(5,1,0) with S=4 harmonics, respectively. The final number of parameters for each of these models is given in Table 1, and it ranges from 3 (SARIMA) to 20 (Beta(4))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py:994: UserWarning: Non-stationary starting seasonal autoregressive Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting seasonal autoregressive'\n",
      "/opt/conda/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py:963: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/conda/lib/python3.6/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#create the estimates assuming measurement error \n",
    "submit_confirmed=[]\n",
    "submit_fatal=[]\n",
    "for i in df1:\n",
    "    # contrived dataset\n",
    "    data = i.ConfirmedCases.astype('int32').tolist()\n",
    "    # fit model\n",
    "    try:\n",
    "        #model = SARIMAX(data, order=(2,1,0), seasonal_order=(1,1,0,12),measurement_error=True)#seasonal_order=(1, 1, 1, 1))\n",
    "        model = SARIMAX(data, order=(1,1,0), seasonal_order=(1,1,0,12),measurement_error=True)#seasonal_order=(1, 1, 1, 1))\n",
    "        #model = SARIMAX(data, order=(1,1,0), seasonal_order=(0,1,0,12),measurement_error=True)#seasonal_order=(1, 1, 1, 1))\n",
    "        #model = ARIMA(data, order=(3,1,2))\n",
    "        model_fit = model.fit(disp=False)\n",
    "        # make prediction\n",
    "        predicted = model_fit.predict(len(data), len(data)+34)\n",
    "        new=np.concatenate((np.array(data),np.array([int(num) for num in predicted])),axis=0)\n",
    "        submit_confirmed.extend(list(new[-43:]))\n",
    "    except:\n",
    "        submit_confirmed.extend(list(data[-10:-1]))\n",
    "        for j in range(34):\n",
    "            submit_confirmed.append(data[-1]*2)\n",
    "    \n",
    "    # contrived dataset\n",
    "    data = i.Fatalities.astype('int32').tolist()\n",
    "    # fit model\n",
    "    try:\n",
    "        #model = SARIMAX(data, order=(1,0,0), seasonal_order=(0,1,1,12),measurement_error=True)#seasonal_order=(1, 1, 1, 1))\n",
    "        model = SARIMAX(data, order=(1,1,0), seasonal_order=(1,1,0,12),measurement_error=True)#seasonal_order=(1, 1, 1, 1))\n",
    "        #model = ARIMA(data, order=(3,1,2))\n",
    "        model_fit = model.fit(disp=False)\n",
    "        # make prediction\n",
    "        predicted = model_fit.predict(len(data), len(data)+34)\n",
    "        new=np.concatenate((np.array(data),np.array([int(num) for num in predicted])),axis=0)\n",
    "        submit_fatal.extend(list(new[-43:]))\n",
    "    except:\n",
    "        submit_fatal.extend(list(data[-10:-1]))\n",
    "        for j in range(34):\n",
    "            submit_fatal.append(data[-1]*2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an alternative fatality metric \n",
    "#submit_fatal = [i * .005 for i in submit_confirmed]\n",
    "#print(submit_fatal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the submission file \n",
    "df_submit=pd.concat([pd.Series(np.arange(1,1+len(submit_confirmed))),pd.Series(submit_confirmed),pd.Series(submit_fatal)],axis=1)\n",
    "df_submit=df_submit.fillna(method='pad').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1  2\n",
       "0  1  22  0\n",
       "1  2  22  0\n",
       "2  3  24  0\n",
       "3  4  24  0\n",
       "4  5  40  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view submission file \n",
    "df_submit.head()\n",
    "#df_submit.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ForecastId Country_Region Province_State        Date\n",
       "0           1    Afghanistan            NaN  2020-03-19\n",
       "1           2    Afghanistan            NaN  2020-03-20\n",
       "2           3    Afghanistan            NaN  2020-03-21\n",
       "3           4    Afghanistan            NaN  2020-03-22\n",
       "4           5    Afghanistan            NaN  2020-03-23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine the test file \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the submission file info to the test data set \n",
    "#rename the columns \n",
    "df_submit.rename(columns={0: 'ForecastId', 1: 'ConfirmedCases',2: 'Fatalities',}, inplace=True)\n",
    "\n",
    "#join the two data items \n",
    "complete_test= pd.merge(test, df_submit, how=\"left\", on=\"ForecastId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_submit.interpolate(method='pad', xis=0, inplace=True)\n",
    "df_submit.to_csv('submission.csv',header=['ForecastId','ConfirmedCases','Fatalities'],index=False)\n",
    "complete_test.to_csv('complete_test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
